{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoxqXRzOrutmurtRXo0a6z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjmora22/NLP/blob/Codigo_Notebooks/4_Metricas_Conclusiones.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Métricas y conclusiones sobre el modelo Random Forest"
      ],
      "metadata": {
        "id": "x19gHpBcce75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Éstas son las librerías que utilizaré"
      ],
      "metadata": {
        "id": "vyhDtDdxhTcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline # Enlaza diferentes pasos en un \"workflow\"\n",
        "from imblearn.over_sampling import RandomOverSampler # Voy a balancear la muestra, porque resultó muy pequeña para la validación\n",
        "import pickle # Permite guardar/recuperar del disco el modelo Random Forest que vamos a utilizar\n",
        "import joblib # cargar el modelo entrenado a memoria \n",
        "from joblib import load\n",
        "from numpy import loadtxt # para cargar el numpy.array de las proyecciones de validación"
      ],
      "metadata": {
        "id": "VNXl9kWehTzE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr5KRx9Uwq6p",
        "outputId": "1d7ad106-cffe-4776-9e10-447f07621d69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn-intelex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYqbuUkLzWMO",
        "outputId": "6a7900c9-961e-478a-ebf8-1ab21a55a996"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn-intelex in /usr/local/lib/python3.8/dist-packages (2023.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.8/dist-packages (from scikit-learn-intelex) (1.2.2)\n",
            "Requirement already satisfied: daal4py==2023.0.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn-intelex) (2023.0.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from daal4py==2023.0.1->scikit-learn-intelex) (1.22.4)\n",
            "Requirement already satisfied: daal==2023.0.1 in /usr/local/lib/python3.8/dist-packages (from daal4py==2023.0.1->scikit-learn-intelex) (2023.0.1)\n",
            "Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.8/dist-packages (from daal==2023.0.1->daal4py==2023.0.1->scikit-learn-intelex) (2021.8.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall scikit-learn -y\n",
        "\n",
        "!pip install -U scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "ftwfaqoM2H8f",
        "outputId": "a6b87db0-9bc4-4ff5-83ab-1557db424764"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: scikit-learn 1.0.2\n",
            "Uninstalling scikit-learn-1.0.2:\n",
            "  Successfully uninstalled scikit-learn-1.0.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
            "Installing collected packages: scikit-learn\n",
            "Successfully installed scikit-learn-1.2.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearnex import patch_sklearn # Permite el cómputo distribuido\n",
        "patch_sklearn() # Corrige errores en joblib (scikit-learn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezQJpWcM0hQd",
        "outputId": "8fec1ad8-42cd-4217-a882-3385c95ec3fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero recupero el dataframe y el modelo entrenado --> "
      ],
      "metadata": {
        "id": "xuoExgQEhV1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga los datos de validación\n",
        "X_val = pd.read_csv('X_val.csv')\n",
        "y_val = pd.read_csv('y_val.csv', header='infer')\n",
        "X_train = pd.read_csv('X_train.csv')\n",
        "y_train = pd.read_csv('y_train.csv')\n",
        "\n",
        "#oversampler = RandomOverSampler()\n",
        "#X_val, y_val = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Carga el modelo random forest y el vectorizador pre-entrenado\n",
        "rf_model = joblib.load('random_forest_model.joblib')\n",
        "vectorizer = joblib.load('vectorizer.pkl')\n",
        "\n",
        "# Hago fit de X_val para el vectorizador \n",
        "#vectorizer = TfidfVectorizer(max_df=1, ngram_range=(1, 2))\n",
        "#X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transforma los datos de validación usando el vectorizador cargado\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "\n",
        "# Realiza predicciones en los datos transformados usando el modelo cargado\n",
        "y_pred = loadtxt('rfc_val_pred.csv', delimiter=',')"
      ],
      "metadata": {
        "id": "nnPKHAuzci6u"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_vectorized.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t61jPSavrPb",
        "outputId": "b9c6fedb-6d2a-4d95-e419-b8436eb4e9de"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 117355)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y_val.shape\n",
        "#y_pred.shape\n",
        "#X_val.shape\n",
        "#X_train.shape\n",
        "#X_val_vectorized.shape\n",
        "print(y_val.value_counts())"
      ],
      "metadata": {
        "id": "RBUyooZ5OvjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a7bde1-0a50-429a-ca7a-4ce633e16992"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "overall\n",
            "5          947\n",
            "1          550\n",
            "4          331\n",
            "3          227\n",
            "2          186\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tomando en cuenta los resultados del modelo escogido, calcularé las métricas específicas que validen la bondad del modelo, utilizo los datos de validación. "
      ],
      "metadata": {
        "id": "JCaxTdrd7pLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcula la precisión (accuracy) del modelo\n",
        "precision = accuracy_score(y_val, y_pred)\n",
        "print(f\"Precisión: {precision:.4f}\")\n",
        "\n",
        "# Imprime la matriz de confusión y el reporte de clasificación\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "print(\"Matriz de confusión:\")\n",
        "print(cm)\n",
        "cr = classification_report(y_val, y_pred)\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "c0O9DVK6hGOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ead36e2-f9d7-4867-ab4d-66011de81837"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión: 0.5872\n",
            "Matriz de confusión:\n",
            "[[413   6   2   0 129]\n",
            " [104   2   4   3  73]\n",
            " [ 92   0   6   6 123]\n",
            " [ 44   2   0  15 270]\n",
            " [ 61   2   1   3 880]]\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.58      0.75      0.65       550\n",
            "           2       0.17      0.01      0.02       186\n",
            "           3       0.46      0.03      0.05       227\n",
            "           4       0.56      0.05      0.08       331\n",
            "           5       0.60      0.93      0.73       947\n",
            "\n",
            "    accuracy                           0.59      2241\n",
            "   macro avg       0.47      0.35      0.31      2241\n",
            "weighted avg       0.54      0.59      0.49      2241\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se confirma el nivel de accuracy encontrado en train y test. Aunque el modelo es muy mejorable, se comporta de manera consistente con lo hallado. "
      ],
      "metadata": {
        "id": "dL4uJtQGDHss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conclusiones FINALES"
      ],
      "metadata": {
        "id": "KBsgHLe67z5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. De un análisis exploratorio, se intuye que la satisfacción de los clientes está relacionada con el funcionamiento del producto/servicio y con su facilidad de uso. En los n-gramas fue claro tanto en el análisis de calificaciones postivas como en negativas la presencia de palabras relacionadas con estos dos conceptos.  \n",
        "2. Se detectó la presencia de sugerencias de mejora de manera importante. Esto genera una fuente de información importante para los vendedores de Amazon. \n",
        "3. He elegido Naive Bayes Multinomial y Random Forest Classifier. \n",
        "4. Elegí Naive Bayes pues asume que la aparición de una palabra es independiente de la ocurrencia de otras palabras. Esto simplifica el algoritmo y lo hace más eficiente. En el caso de esta práctica, etiquetamos los datos con un sentimiento positivo o negativo y entrenamos al modelo para predecir el sentimiento (estrellas) de reviews futuras.  \n",
        "5. En el caso de Random Forest Classifier, busca predecir el sentimiento, en base a agrupar elementos etiquetados de manera aleatoria y cada árbol se entrena sobre estos elementos. El resultado se obtiene de la predicción conjunta de varios árboles (el bosque). Permite el manejo de datasets grandes con alta dimensionalidad (gran cantidad de palabras), por lo que puede favorecer el overfitting. Random Forest limitar este riesgo al crear bosques de manera random. \n",
        "6. Estos modelos brindan una alta precisión en tareas de clasificación de texto. También son una buena alternativa en situaciones de alta dimensionalidad. \n",
        "7. Naive Bayes permite trabajar ambientes donde se encuentra información con \"ruido\". En nuestro caso, texto escrito por los usuarios. \n",
        "8. Ambos modelos son relativamente rápidos para entrenarse y hacer predicciones (aunque en las pruebas Random Forest ha tomado 2 horas vs Naive Bayes que lo resuelve en segundos).\n",
        "9. Al evaluar los resultados del modelo, se observa que el método de Random Forest Classifier supera al de Naive Bayes en términos de Recall, lo que indica que el modelo de Random Forest tiene un mejor desempeño en identificar los verdaderos positivos, es decir, los casos en que el modelo predijo correctamente que una reseña era positiva o negativa.\n",
        "10. En términos de precisión, los modelos obtienen puntajes similares. Esto indica que ambos modelos logran identificar correctamente un porcentaje aceptable de las reseñas, pero no son perfectos y pueden cometer algunos errores.\n",
        "11. Es importante destacar que se puede seguir mejorando la precisión y el rendimiento del modelo mediante la optimización de los hiperparámetros o la incorporación de otras técnicas de preprocesamiento.\n",
        "12. El análisis exploratorio y la implementación de modelos de clasificación de texto en esta práctica demuestran la utilidad de las técnicas de procesamiento de lenguaje natural para analizar grandes cantidades de datos no estructurados y obtener información valiosa para la toma de decisiones en el ámbito empresarial.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KpJJg1yp71sN"
      }
    }
  ]
}